
# Copyright 2016 Intuit
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

[main]

# All ${} variables will be replaced by Jenkins during build, do not edit.

# ===============
# General configs
# ===============

dataset_name=example

source_root=/thrive_sample_data

# Assumed to be present in nfs_dataset_path (defined in NFS configs)
mapper=mapper.py

# Assumed to be present in nfs_dataset_path (defined in NFS configs)
workflow_xml=workflow.xml

# ============
# NFS configs
# ============

nfs_root=/thrive

nfs_dataset_path=%(nfs_root)s/datasets/%(dataset_name)s

nfs_resource_path=%(nfs_root)s/resources

nfs_log_path=%(nfs_root)s/logs/%(dataset_name)s

nfs_workflow_properties_path=%(nfs_dataset_path)s/workflow-properties

nfs_jobinput_properties_path=%(nfs_dataset_path)s/jobinput-properties

nfs_dragline_lib=%(nfs_resource_path)s/lib

# ============
# Hive configs
# ============

hive_db=default

hive_table=%(dataset_name)s

hive_columns=hive_columns.csv

hive_ddl=hive_schema.sql

hive_last_load_folder=

# ===============
# Vertica configs
# ===============

vertica_load=false

vertica_db=Analytics

vertica_schema=thrive

vertica_table=%(hive_table)s

vertica_rejected_data_table=%(vertica_table)s__rejected_data

vertica_columns=vertica_columns.csv

vertica_ddl=vertica_schema.sql

vertica_vsql_path=/opt/vertica/bin/vsql

vertica_krb_svcname=vertica_kerberos_service_name

vertica_krb_host=kerberoshost.company.net

vertica_host=verticahost.company.net

vertica_port=0000

vertica_user=headless_user

vertica_rollback_key=event_id

vertica_roles=thrive_dev

vertica_projection_keys=event_id

vertica_segmentation_keys=event_id

vertica_partition_expr=extract(month from src_timestamp)

# ===================
# HDFS and MR configs
# ===================

hdfs_user=root

hdfs_root=/user/root/thrive

hdfs_resource_path=%(hdfs_root)s/%(dataset_name)s

webhdfs_root=http://localhost:50070/webhdfs/v1

target_root=/user/hive/warehouse/%(hive_db)s.db/%(hive_table)s

namenode=hdfs://quickstart.cloudera

jobtracker=localhost:8032

mr_chunk_size=hour

mr_num_reducers=1

# Other options for codecs
# org.apache.hadoop.io.compress.BZip2Codec
mr_output_codec=org.apache.hadoop.io.compress.GzipCodec

# ================
# Splunk configs
# ================

splunk_index=splunk_index_name

splunk_env=preprod

splunk_bu_emails=emails.txt

splunk_url=https://splunkhost.corp.company.net:0000/servicesNS

splunk_app=splunk_app

splunk_int_emails=email_list.txt

# ================
# Source configs
# ================

folder_processing_delay=1

# ================
# NewRelic configs
# ================

newrelic_dataset_name=thrive_test

newrelic_url=https://api.newrelic.com/v2/applications/id/path/data.json